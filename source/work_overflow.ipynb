{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-15T10:41:35.495810Z",
     "start_time": "2025-05-15T10:41:33.299375Z"
    }
   },
   "source": [
    "from utils.util import *\n",
    "from ultralytics import RTDETR\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T10:58:14.479441Z",
     "start_time": "2025-05-15T10:58:14.098435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "detector = RTDETR(\"../models/object_detection.pt\")\n",
    "\n",
    "classifier = get_pretrained_resnet(num_classes=1, pretrained=False)\n",
    "classifier.load_state_dict(torch.load(\"../models/defect_detection_model.pth\"))\n",
    "classifier.to(DEVICE)\n",
    "\n",
    "detectable_classes = {7:0, 5:1, 11:2, 1:4}\n",
    "class_to_model = {0 : \"defect_detection_glass_model.pth\", 1 : \"defect_detection_lighting_model.pth\", 2: \"defect_detection_polymer_model.pth\", 4: \"defect_detection_yoke_model.pth\"}\n",
    "class_to_problem = {0 : \"Missing cap\", 1 : \"Rust\", 2: \"Rust\", 4: \"Rust\"}"
   ],
   "id": "9c0b7e75c17544ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 loaded. Final layer replaced for 1 output features.\n",
      "Only the final layer will be trained initially.\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2d1c7356968e50"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:05:39.243209Z",
     "start_time": "2025-05-15T11:05:39.240672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = {}\n",
    "\n",
    "def load_models():\n",
    "    for i, v in class_to_model.items():\n",
    "        model_path = os.path.join(\"/Users/azizbek/Documents/Projects/PowerLine/models\", v)\n",
    "        model = get_pretrained_resnet(num_classes=1, pretrained=False)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model.eval()\n",
    "        models[i] = model"
   ],
   "id": "ddf372c1a5c9c28",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:05:46.333274Z",
     "start_time": "2025-05-15T11:05:46.331300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_model(class_id):\n",
    "    return models[class_id]"
   ],
   "id": "236888c92cba9929",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:27:50.888449Z",
     "start_time": "2025-05-15T11:27:50.884124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_full_pipeline(img, image_path:str|Path, save_dir:Path|None=None, pad:int=0):\n",
    "    \"\"\"\n",
    "    • Detect parts with REDETR\n",
    "    • Crop each part\n",
    "    • Run defect classifier on the crops\n",
    "    • Optionally save crops for inspection\n",
    "    \"\"\"\n",
    "    original_img = img\n",
    "\n",
    "    if img is None:\n",
    "        original_img = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    img_defections   = original_img.copy()          # red boxes will go here\n",
    "    draw    = ImageDraw.Draw(img_defections)\n",
    "\n",
    "    results = detector.predict(original_img)\n",
    "    detections = []\n",
    "    for result in results:\n",
    "        # print(f\"  Type of result.boxes: {type(result.boxes)}\")\n",
    "        # print(f\"  Value of result.boxes: {result.boxes}\")\n",
    "        if result.boxes is not None and len(result.boxes) > 0:\n",
    "            boxes = result.boxes\n",
    "            confidences = boxes.conf\n",
    "            cls_indices = boxes.cls\n",
    "\n",
    "            # print(f\"  Type of boxes: {type(boxes)}\")\n",
    "            # print(f\"  Type of confidences: {type(confidences)}\")\n",
    "            # print(f\"  Type of cls_indices: {type(cls_indices)}\")\n",
    "\n",
    "            for box, confidence, class_id in zip(boxes.xyxy, confidences, cls_indices):\n",
    "                x1, y1, x2, y2 = box.tolist()\n",
    "                confidence_value = confidence.item()\n",
    "\n",
    "                c_id = int(class_id)\n",
    "                class_name = result.names[c_id]\n",
    "\n",
    "                print(f\"Object Detected {class_name}-{c_id} with confidence: {confidence_value:.2f} at ({x1:.0f}, {y1:.0f}), ({x2:.0f}, {y2:.0f})\")\n",
    "                id = detectable_classes.get(c_id)\n",
    "                print(f\"Class id is now: {id}\")\n",
    "                if id is not None:\n",
    "                    crop = crop_object(original_img, box)\n",
    "                    model = get_model(id)\n",
    "                    prob, label = predict_single(crop, model, DEVICE)\n",
    "                    print(f\"    Detected defect {label} with confidence: {prob:.2f}\")\n",
    "                    if label != 0:\n",
    "                        print(f\"    Detected defect: {class_to_problem[id]} with confidence: {prob:.2f}\")\n",
    "                        draw.rectangle([(x1, y1), (x2, y2)], outline=\"red\", width=1)\n",
    "                        draw.text((x1, y1 - 12), class_to_problem[id], fill=\"red\")\n",
    "                        detections.append({\"id\": id, \"prob\": prob, \"label\": label, \"type\": class_to_problem[id], \"box\": box, \"confidence\": confidence})\n",
    "\n",
    "\n",
    "            img_object_detection = Image.fromarray(result.plot().astype('uint8')) # Convert to PIL Image\n",
    "            save_path = f\"./{save_dir}/object_{os.path.basename(image_path)}\"\n",
    "            save_path_d = f\"./{save_dir}/detected_{os.path.basename(image_path)}\"\n",
    "            img_object_detection.save(save_path)  # Now you can use .save()\n",
    "            print(f\"  Saved annotated image to: {save_path}\")\n",
    "            if detections:\n",
    "                img_defections.save(save_path_d)  # Now you can use .save()\n",
    "                print(f\"  Saved defected image to: {save_path}\")\n",
    "            else:\n",
    "                print(\"  No defects detected\")\n",
    "            return result, detections\n",
    "        else:\n",
    "            print(\"  No objects detected in this image.\")"
   ],
   "id": "176481ece009a604",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T11:31:44.964473Z",
     "start_time": "2025-05-15T11:31:42.997151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_models()\n",
    "print(f\"Loaded models: {len(models)}\")\n",
    "test_img = '/Users/azizbek/Downloads/tok-stoyka.png'\n",
    "test_img = '/Users/azizbek/Documents/Projects/PowerLine/data/InsPLAD-fault/defect_supervised/yoke-suspension/val/rust/01-06-2021_DJI_0385_114.jpg'\n",
    "\n",
    "outputs  = run_full_pipeline(img = None, image_path = test_img, save_dir=\"debug_crops\")\n",
    "print(outputs)"
   ],
   "id": "fdaf8067d2aa2f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet18 loaded. Final layer replaced for 1 output features.\n",
      "Only the final layer will be trained initially.\n",
      "ResNet18 loaded. Final layer replaced for 1 output features.\n",
      "Only the final layer will be trained initially.\n",
      "ResNet18 loaded. Final layer replaced for 1 output features.\n",
      "Only the final layer will be trained initially.\n",
      "ResNet18 loaded. Final layer replaced for 1 output features.\n",
      "Only the final layer will be trained initially.\n",
      "Loaded models: 4\n",
      "\n",
      "0: 640x640 1 yoke, 1 yoke suspension, 797.3ms\n",
      "Speed: 2.2ms preprocess, 797.3ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Object Detected yoke suspension-1 with confidence: 0.90 at (43, 2), (269, 478)\n",
      "Class id is now: 4\n",
      "    Detected defect 0 with confidence: 0.08\n",
      "Object Detected yoke-0 with confidence: 0.60 at (53, 0), (483, 485)\n",
      "Class id is now: None\n",
      "  Saved annotated image to: ./debug_crops/object_01-06-2021_DJI_0385_114.jpg\n",
      "  No defects detected\n",
      "(ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: None\n",
      "names: {0: 'yoke', 1: 'yoke suspension', 2: 'spacer', 3: 'stockbridge damper', 4: 'lightning rod shackle', 5: 'lightning rod suspension', 6: 'polymer insulator', 7: 'glass insulator', 8: 'tower id plate', 9: 'vari-grip', 10: 'polymer insulator lower shackle', 11: 'polymer insulator upper shackle', 12: 'polymer insulator tower shackle', 13: 'glass insulator big shackle', 14: 'glass insulator small shackle', 15: 'glass insulator tower shackle', 16: 'spiral damper', 17: 'sphere'}\n",
      "obb: None\n",
      "orig_img: array([[[162, 173, 157],\n",
      "        [162, 173, 157],\n",
      "        [161, 172, 156],\n",
      "        ...,\n",
      "        [168, 181, 165],\n",
      "        [168, 181, 165],\n",
      "        [169, 182, 166]],\n",
      "\n",
      "       [[168, 179, 163],\n",
      "        [168, 179, 163],\n",
      "        [167, 178, 162],\n",
      "        ...,\n",
      "        [166, 179, 163],\n",
      "        [166, 179, 163],\n",
      "        [167, 180, 164]],\n",
      "\n",
      "       [[173, 184, 168],\n",
      "        [172, 183, 167],\n",
      "        [171, 182, 166],\n",
      "        ...,\n",
      "        [163, 176, 160],\n",
      "        [164, 177, 161],\n",
      "        [164, 177, 161]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[102, 129, 109],\n",
      "        [104, 131, 111],\n",
      "        [108, 135, 115],\n",
      "        ...,\n",
      "        [108, 134, 118],\n",
      "        [110, 136, 120],\n",
      "        [111, 137, 121]],\n",
      "\n",
      "       [[112, 139, 119],\n",
      "        [113, 140, 120],\n",
      "        [115, 142, 122],\n",
      "        ...,\n",
      "        [106, 132, 116],\n",
      "        [107, 133, 117],\n",
      "        [109, 135, 119]],\n",
      "\n",
      "       [[119, 146, 126],\n",
      "        [119, 146, 126],\n",
      "        [120, 147, 127],\n",
      "        ...,\n",
      "        [103, 129, 113],\n",
      "        [105, 131, 115],\n",
      "        [106, 132, 116]]], dtype=uint8)\n",
      "orig_shape: (485, 485)\n",
      "path: 'image0.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs/detect/predict'\n",
      "speed: {'preprocess': 2.239666999230394, 'inference': 797.2563750008703, 'postprocess': 0.25208399893017486}, [])\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:14:07.132186Z",
     "start_time": "2025-05-14T10:14:07.126200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os, random, cv2, torch\n",
    "from pathlib import Path\n",
    "\n",
    "# ─── CONFIG ───────────────────────────────────────────────────────────────────\n",
    "DEFECT_THR  = 0.5            # show box only if defect‑prob ≥ this\n",
    "PAD         = 4              # pixels of padding when cropping\n",
    "\n",
    "# simple RGB‑to‑tensor preproc matching your classifier\n",
    "def to_tensor(img_bgr):\n",
    "    return ( torch.from_numpy(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB))\n",
    "             .permute(2,0,1).float()/255. ).unsqueeze(0)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def detect_and_filter(image_path: str|Path):\n",
    "    im_bgr   = cv2.imread(str(image_path))\n",
    "    h, w     = im_bgr.shape[:2]\n",
    "\n",
    "    # 1 ▸ DETECT PARTS\n",
    "    results  = detector.predict(im_bgr, conf=0.65, device=DEVICE, verbose=False)[0]\n",
    "    if len(results.boxes) == 0:                      # → nothing at all\n",
    "        return im_bgr, []\n",
    "\n",
    "    boxes_xyxy = results.boxes.xyxy.cpu().numpy()    # [N,4]\n",
    "    part_names = [results.names[int(c)] for c in results.boxes.cls]\n",
    "\n",
    "    keep, info = [], []                              # filtered indices & meta\n",
    "    # 2 ▸ CROP ▸ CLASSIFY EACH BOX\n",
    "    for idx, (x1,y1,x2,y2) in enumerate(boxes_xyxy.astype(int)):\n",
    "        # crop with small padding\n",
    "        x1p,y1p = max(x1-PAD,0), max(y1-PAD,0)\n",
    "        x2p,y2p = min(x2+PAD,w-1), min(y2+PAD,h-1)\n",
    "        crop    = im_bgr[y1p:y2p, x1p:x2p]\n",
    "\n",
    "        prob = torch.sigmoid(classifier(to_tensor(crop).to(DEVICE))).item()\n",
    "        if prob >= DEFECT_THR:                       # defective → keep\n",
    "            keep.append(idx)\n",
    "            info.append((x1,y1,x2,y2, part_names[idx], prob))\n",
    "\n",
    "    return im_bgr, info                              # original image + kept boxes\n",
    "\n",
    "# ─── TEST LOOP ────────────────────────────────────────────────────────────────\n"
   ],
   "id": "2f3eceffdd5084cb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T10:23:57.230836Z",
     "start_time": "2025-05-14T10:23:46.866954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_test_images = 5\n",
    "# Path to your directory of random images\n",
    "image_dir = \"../data/InsPLAD-det/val/images\"\n",
    "image_dir = \"../data/InsPLAD-fault/unsupervised_anomaly_detection/glass-insulator/test/missingcap\"\n",
    "\n",
    "# Get a list of all image files\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]\n",
    "\n",
    "for _ in range(num_test_images):\n",
    "    img_path = random.choice(image_files)\n",
    "    print(f\"\\n--- Processing image: {os.path.basename(img_path)} ---\")\n",
    "\n",
    "    img_bgr, bad_parts = detect_and_filter(img_path)\n",
    "    if not bad_parts:\n",
    "        print(\"  No defects found.\")\n",
    "        continue\n",
    "\n",
    "    # draw only “bad” boxes\n",
    "    for (x1,y1,x2,y2, label, prob) in bad_parts:\n",
    "        cv2.rectangle(img_bgr, (x1,y1), (x2,y2), (0,0,255), 2)          # red box\n",
    "        cv2.putText(img_bgr,\n",
    "                    f\"{label}: {prob:.2f}\",\n",
    "                    (x1, max(y1-5,12)),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0,0,255), 1, cv2.LINE_AA)\n",
    "        print(f\"    DEFECT {label}  p={prob:.2f}  box=({x1},{y1})–({x2},{y2})\")\n",
    "\n",
    "    save_path = f\"../results/defect_detection/defects_{os.path.basename(img_path)}\"\n",
    "    cv2.imwrite(save_path, img_bgr)\n",
    "    print(f\"  Saved annotated defects‑only image to: {save_path}\")"
   ],
   "id": "6920529b8dd84de5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing image: Fotos 21-10-2020_DJI_0557_cadeia_isolador_vidro_1630.jpg ---\n",
      "  No defects found.\n",
      "\n",
      "--- Processing image: Fotos 21-10-2020_DJI_0537_cadeia_isolador_vidro_1615.jpg ---\n",
      "  No defects found.\n",
      "\n",
      "--- Processing image: Fotos 07-12-2020_DJI_0134_cadeia_isolador_vidro_1338.jpg ---\n",
      "  No defects found.\n",
      "\n",
      "--- Processing image: Fotos 03-12-2020_DJI_0361_cadeia_isolador_vidro_911.jpg ---\n",
      "  No defects found.\n",
      "\n",
      "--- Processing image: Fotos 03-12-2020_DJI_0361_cadeia_isolador_vidro_912.jpg ---\n",
      "  No defects found.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T10:21:14.240454Z",
     "start_time": "2025-05-15T10:21:14.236192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"../data/InsPLAD-det/data.yaml\") as f:\n",
    "    class_names = yaml.safe_load(f)[\"names\"]\n",
    "\n",
    "# Later:\n",
    "print(class_names)"
   ],
   "id": "9c53b75bf3b1415",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yoke', 'yoke suspension', 'spacer', 'stockbridge damper', 'lightning rod shackle', 'lightning rod suspension', 'polymer insulator', 'glass insulator', 'tower id plate', 'vari-grip', 'polymer insulator lower shackle', 'polymer insulator upper shackle', 'polymer insulator tower shackle', 'glass insulator big shackle', 'glass insulator small shackle', 'glass insulator tower shackle', 'spiral damper', 'sphere']\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
